{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE-Lens eval repro\n",
    "\n",
    "The demo notebook was broken - here is a fixed version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import plotly.express as px\n",
    "\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from transformer_lens import utils\n",
    "from typing import Dict\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from sae_lens.training.session_loader import LMSparseAutoencoderSessionloader\n",
    "# from sae_lens.analysis.visualizer.data_fns import get_feature_data, FeatureData\n",
    "from sae_vis.data_fetching_fns import get_feature_data, FeatureData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lifting from https://github.com/jbloomAus/SAELens/blob/main/tutorials/evaluating_your_sae.ipynb\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.set_grad_enabled(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the SAE for layer 0 (the one with the Magikarps)\n",
    "\n",
    "REPO_ID = \"jbloom/GPT2-Small-SAEs\"\n",
    "layer = 0  # any layer from 0 - 11 works here\n",
    "FILENAME = f\"final_sparse_autoencoder_gpt2-small_blocks.{layer}.hook_resid_pre_24576.pt\"\n",
    "\n",
    "path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then load the SAE, dataset and model using the session loader\n",
    "model, sparse_autoencoders, activation_store = (\n",
    "    LMSparseAutoencoderSessionloader.load_session_from_pretrained(path=path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sae in enumerate(sparse_autoencoders):\n",
    "    hyp = sae.cfg\n",
    "    print(\n",
    "        f\"{i}: Layer {hyp.hook_point_layer}, p_norm {hyp.lp_norm}, alpha {hyp.l1_coefficient}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick which sae you wnat to evaluate. Default is 0\n",
    "sparse_autoencoder = list(sparse_autoencoders)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the Autoencoder\n",
    "\n",
    "sparse_autoencoder.eval()  # prevents error if we're expecting a dead neuron mask for who grads\n",
    "with torch.no_grad():\n",
    "    batch_tokens = activation_store.get_batch_tokens()\n",
    "    _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "    sae_out, feature_acts, loss, mse_loss, l1_loss, _ = sparse_autoencoder(\n",
    "        cache[sparse_autoencoder.cfg.hook_point]\n",
    "    )\n",
    "    del cache\n",
    "\n",
    "    # ignore the bos token, get the number of features that activated in each token, averaged accross batch and position\n",
    "    l0 = (feature_acts[:, 1:] > 0).float().sum(-1).detach()\n",
    "    print(\"average l0\", l0.mean().item())\n",
    "    px.histogram(l0.flatten().cpu().numpy()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we want to do a reconstruction test.\n",
    "def reconstr_hook(activation, hook, sae_out):\n",
    "    return sae_out\n",
    "\n",
    "\n",
    "def zero_abl_hook(activation, hook):\n",
    "    return torch.zeros_like(activation)\n",
    "\n",
    "\n",
    "print(\"Orig\", model(batch_tokens, return_type=\"loss\").item())\n",
    "print(\n",
    "    \"reconstr\",\n",
    "    model.run_with_hooks(\n",
    "        batch_tokens,\n",
    "        fwd_hooks=[\n",
    "            (\n",
    "                utils.get_act_name(\"resid_pre\", 10),\n",
    "                partial(reconstr_hook, sae_out=sae_out),\n",
    "            )\n",
    "        ],\n",
    "        return_type=\"loss\",\n",
    "    ).item(),\n",
    ")\n",
    "print(\n",
    "    \"Zero\",\n",
    "    model.run_with_hooks(\n",
    "        batch_tokens,\n",
    "        return_type=\"loss\",\n",
    "        fwd_hooks=[(utils.get_act_name(\"resid_pre\", 10), zero_abl_hook)],\n",
    "    ).item(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific Capability Test\n",
    "example_prompt = \"When John and Mary went to the shops, John gave the bag to\"\n",
    "example_answer = \" Mary\"\n",
    "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)\n",
    "\n",
    "logits, cache = model.run_with_cache(example_prompt, prepend_bos=True)\n",
    "tokens = model.to_tokens(example_prompt)\n",
    "sae_out, feature_acts, loss, mse_loss, l1_loss, _ = sparse_autoencoder(\n",
    "    cache[sparse_autoencoder.cfg.hook_point]\n",
    ")\n",
    "\n",
    "\n",
    "def reconstr_hook(activations, hook, sae_out):\n",
    "    return sae_out\n",
    "\n",
    "\n",
    "def zero_abl_hook(mlp_out, hook):\n",
    "    return torch.zeros_like(mlp_out)\n",
    "\n",
    "\n",
    "hook_point = sparse_autoencoder.cfg.hook_point\n",
    "\n",
    "print(\"Orig\", model(tokens, return_type=\"loss\").item())\n",
    "print(\n",
    "    \"reconstr\",\n",
    "    model.run_with_hooks(\n",
    "        tokens,\n",
    "        fwd_hooks=[\n",
    "            (\n",
    "                hook_point,\n",
    "                partial(reconstr_hook, sae_out=sae_out),\n",
    "            )\n",
    "        ],\n",
    "        return_type=\"loss\",\n",
    "    ).item(),\n",
    ")\n",
    "print(\n",
    "    \"Zero\",\n",
    "    model.run_with_hooks(\n",
    "        tokens,\n",
    "        return_type=\"loss\",\n",
    "        fwd_hooks=[(hook_point, zero_abl_hook)],\n",
    "    ).item(),\n",
    ")\n",
    "\n",
    "\n",
    "with model.hooks(\n",
    "    fwd_hooks=[\n",
    "        (\n",
    "            hook_point,\n",
    "            partial(reconstr_hook, sae_out=sae_out),\n",
    "        )\n",
    "    ]\n",
    "):\n",
    "    utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating feature interfaces\n",
    "vals, inds = torch.topk(feature_acts[0, -1].detach().cpu(), 10)\n",
    "px.bar(x=[str(i) for i in inds], y=vals).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_vis.data_config_classes import (\n",
    "    # ActsHistogramConfig,\n",
    "    # Column,\n",
    "    # FeatureTablesConfig,\n",
    "    SaeVisConfig)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DASHBOARD_FOLDER = 'dashboards'\n",
    "\n",
    "\n",
    "vocab_dict = model.tokenizer.vocab\n",
    "vocab_dict = {\n",
    "    v: k.replace(\"Ä \", \" \").replace(\"\\n\", \"\\\\n\") for k, v in vocab_dict.items()\n",
    "}\n",
    "\n",
    "vocab_dict_filepath = Path(os.getcwd()) / \"vocab_dict.json\"\n",
    "if not vocab_dict_filepath.exists():\n",
    "    with open(vocab_dict_filepath, \"w\") as f:\n",
    "        json.dump(vocab_dict, f)\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "data = load_dataset(\n",
    "    \"NeelNanda/c4-code-20k\", split=\"train\"\n",
    ")  # currently use this dataset to avoid deal with tokenization while streaming\n",
    "tokenized_data = utils.tokenize_and_concatenate(data, model.tokenizer, max_length=128)\n",
    "tokenized_data = tokenized_data.shuffle(42)\n",
    "all_tokens = tokenized_data[\"tokens\"]\n",
    "\n",
    "\n",
    "# Currently, don't think much more time can be squeezed out of it. Maybe the best saving would be to\n",
    "# make the entire sequence indexing parallelized, but that's possibly not worth it right now.\n",
    "\n",
    "max_batch_size = 512\n",
    "total_batch_size = 4096 * 5\n",
    "feature_idx = list(inds.flatten().cpu().numpy())\n",
    "# max_batch_size = 512\n",
    "# total_batch_size = 16384\n",
    "# feature_idx = list(range(1000))\n",
    "\n",
    "tokens = all_tokens[:total_batch_size]\n",
    "\n",
    "\n",
    "feature_vis_params = SaeVisConfig(\n",
    "    hook_point=sparse_autoencoder.cfg.hook_point,\n",
    "    minibatch_size_features=256,\n",
    "    minibatch_size_tokens=64,\n",
    "    features=feature_idx,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pickle_filepath = Path(os.getcwd()) / \"feature_data.pickle\"\n",
    "\n",
    "if not os.path.exists(pickle_filepath):\n",
    "\n",
    "    feature_data: Dict[int, FeatureData] = get_feature_data(\n",
    "        encoder=sparse_autoencoder,\n",
    "        model=model,\n",
    "        tokens=tokens,\n",
    "        cfg=feature_vis_params\n",
    "    )\n",
    "\n",
    "    feature_data.model = model\n",
    "\n",
    "    with open(pickle_filepath, \"wb\") as f:\n",
    "        pickle.dump(feature_data, f)\n",
    "\n",
    "else:\n",
    "    with open(pickle_filepath, \"rb\") as f:\n",
    "        feature_data = pickle.load(f)\n",
    "\n",
    "for test_idx in feature_data.feature_data_dict:\n",
    "    feature_data.save_feature_centric_vis(\n",
    "        f\"{DASHBOARD_FOLDER}/data_{test_idx:04}.html\",\n",
    "        feature_idx=test_idx,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechinterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
